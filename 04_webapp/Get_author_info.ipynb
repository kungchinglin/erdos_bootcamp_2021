{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Author Information Real-Time\n",
    "\n",
    "When we deploy the web app, we expect to take in the url to a specific reddit post. Then we will need to retrieve necessary information to make a prediction. I noticed that the past history of the author seems to be a very strong predictor, so I want to incorporate that into our web app. The following code chunks will help us retrieve that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime as dt\n",
    "import json\n",
    "import time\n",
    "import praw\n",
    "\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"kxbUr-4PyE7DlQ\",\n",
    "    client_secret=\"Q5rIAPS9IHZ1QgOIkHNY09Y9VMxDsA\",\n",
    "    password=\"AACAXZDE\",\n",
    "    user_agent=\"testscript by u/kc_the_scraper\",\n",
    "    username=\"kc_the_scraper\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPushShiftDataAuthor(after,before, sub, author):\n",
    "    ids = []\n",
    "    while after < before:\n",
    "        params = '&after='+str(int(after))+'&before='+str(int(before))+'&subreddit='+str(sub)+'&author='+str(author)\n",
    "        url = 'https://api.pushshift.io/reddit/search/submission/?size=100' + params\n",
    "        r = requests.get(url)\n",
    "        data = json.loads(r.text)['data']\n",
    "       \n",
    "        ids += list(map(lambda x: x['id'], data))\n",
    "        after = data[-1]['created_utc'] + 1\n",
    "        if len(data) < 100:\n",
    "            break \n",
    "    return ids\n",
    "\n",
    "\n",
    "def getPostHistory(ids, upperLimit = 50):\n",
    "\n",
    "    if not ids:\n",
    "        return 0, 1\n",
    "    \n",
    "    totalScore = 0\n",
    "    \n",
    "    limit = min(len(ids), upperLimit)\n",
    "    \n",
    "    ids = ids[:limit]\n",
    "    \n",
    "    for ID in ids:\n",
    "        Sub = reddit.submission(id = ID)\n",
    "        totalScore += Sub.score\n",
    "    \n",
    "    return limit, totalScore/limit\n",
    "\n",
    "def getAuthorFeatures(after, submissionTime, sub, author):\n",
    "    ids = getPushShiftDataAuthor(after, submissionTime - 1, sub, author)\n",
    "    \n",
    "    return getPostHistory(ids)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End-to-end example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User raccoon-city-crypto has 5 posts in r/wallstreetbets, with an average upvote of 1.0.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://www.reddit.com/r/wallstreetbets/comments/lrxpql/melvin_tomorrow_be_like/'\n",
    "Sub = reddit.submission(url = url)\n",
    "\n",
    "start = dt.datetime(2021,1,1).timestamp()\n",
    "subreddit = Sub.subreddit\n",
    "author = Sub.author\n",
    "end = Sub.created_utc - 1\n",
    "\n",
    "num, avg = getAuthorFeatures(start, end, subreddit, author)\n",
    "\n",
    "print(f\"User {author} has {num} posts in r/{subreddit}, with an average upvote of {avg}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
