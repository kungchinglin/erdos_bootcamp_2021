{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building with `Score` as target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv(\"df_processed.csv\")\n",
    "df_orig.replace(np.nan, \"no_text\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>body_processed</th>\n",
       "      <th>title_processed</th>\n",
       "      <th>author_processed</th>\n",
       "      <th>body_and_title</th>\n",
       "      <th>body_and_author</th>\n",
       "      <th>title_and_author</th>\n",
       "      <th>body_title_and_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finance</td>\n",
       "      <td>1</td>\n",
       "      <td>deleted</td>\n",
       "      <td>top seven companies added trillion value</td>\n",
       "      <td>obrocheetah</td>\n",
       "      <td>deleted top seven companies added trillion value</td>\n",
       "      <td>deleted obrocheetah</td>\n",
       "      <td>top seven companies added trillion value obroc...</td>\n",
       "      <td>deleted top seven companies added trillion val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finance</td>\n",
       "      <td>1</td>\n",
       "      <td>no_text</td>\n",
       "      <td>mogo establishes atm equity program mogo finan...</td>\n",
       "      <td>fintechinshorts</td>\n",
       "      <td>no_text mogo establishes atm equity program mo...</td>\n",
       "      <td>no_text fintechinshorts</td>\n",
       "      <td>mogo establishes atm equity program mogo finan...</td>\n",
       "      <td>no_text mogo establishes atm equity program mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit  score body_processed  \\\n",
       "0   finance      1        deleted   \n",
       "1   finance      1        no_text   \n",
       "\n",
       "                                     title_processed author_processed  \\\n",
       "0           top seven companies added trillion value      obrocheetah   \n",
       "1  mogo establishes atm equity program mogo finan...  fintechinshorts   \n",
       "\n",
       "                                      body_and_title          body_and_author  \\\n",
       "0   deleted top seven companies added trillion value      deleted obrocheetah   \n",
       "1  no_text mogo establishes atm equity program mo...  no_text fintechinshorts   \n",
       "\n",
       "                                    title_and_author  \\\n",
       "0  top seven companies added trillion value obroc...   \n",
       "1  mogo establishes atm equity program mogo finan...   \n",
       "\n",
       "                               body_title_and_author  \n",
       "0  deleted top seven companies added trillion val...  \n",
       "1  no_text mogo establishes atm equity program mo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = df_orig[[\"subreddit\", \"score\",\n",
    "          'body_processed','title_processed', 'author_processed',\n",
    "          'body_and_title', 'body_and_author', 'title_and_author',\n",
    "          'body_title_and_author'\n",
    "         ]]\n",
    "\n",
    "df_.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts with score bigger than average score: 26702\n",
      "Posts with score smaller than average score: 514736\n"
     ]
    }
   ],
   "source": [
    "print (\"Posts with score bigger than average score:\", (np.array(df_['score'].values)>=df_['score'].mean()).sum() )\n",
    "print (\"Posts with score smaller than average score:\", (np.array(df_['score'].values)<df_['score'].mean()).sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarize the Score\n",
    "\n",
    "- Looking into the score distribution barely going above 0 give  us a 60/40 splits.\n",
    "- So, convert the score into less than or equal to 1 or bigger than 1\n",
    "- name that column `score_label`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>body_processed</th>\n",
       "      <th>title_processed</th>\n",
       "      <th>author_processed</th>\n",
       "      <th>body_and_title</th>\n",
       "      <th>body_and_author</th>\n",
       "      <th>title_and_author</th>\n",
       "      <th>body_title_and_author</th>\n",
       "      <th>score_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finance</td>\n",
       "      <td>1</td>\n",
       "      <td>deleted</td>\n",
       "      <td>top seven companies added trillion value</td>\n",
       "      <td>obrocheetah</td>\n",
       "      <td>deleted top seven companies added trillion value</td>\n",
       "      <td>deleted obrocheetah</td>\n",
       "      <td>top seven companies added trillion value obroc...</td>\n",
       "      <td>deleted top seven companies added trillion val...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finance</td>\n",
       "      <td>1</td>\n",
       "      <td>no_text</td>\n",
       "      <td>mogo establishes atm equity program mogo finan...</td>\n",
       "      <td>fintechinshorts</td>\n",
       "      <td>no_text mogo establishes atm equity program mo...</td>\n",
       "      <td>no_text fintechinshorts</td>\n",
       "      <td>mogo establishes atm equity program mogo finan...</td>\n",
       "      <td>no_text mogo establishes atm equity program mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit  score body_processed  \\\n",
       "0   finance      1        deleted   \n",
       "1   finance      1        no_text   \n",
       "\n",
       "                                     title_processed author_processed  \\\n",
       "0           top seven companies added trillion value      obrocheetah   \n",
       "1  mogo establishes atm equity program mogo finan...  fintechinshorts   \n",
       "\n",
       "                                      body_and_title          body_and_author  \\\n",
       "0   deleted top seven companies added trillion value      deleted obrocheetah   \n",
       "1  no_text mogo establishes atm equity program mo...  no_text fintechinshorts   \n",
       "\n",
       "                                    title_and_author  \\\n",
       "0  top seven companies added trillion value obroc...   \n",
       "1  mogo establishes atm equity program mogo finan...   \n",
       "\n",
       "                               body_title_and_author  score_label  \n",
       "0  deleted top seven companies added trillion val...            1  \n",
       "1  no_text mogo establishes atm equity program mo...            1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_[\"score_label\"] = df_[\"score\"].apply(lambda x: int(x<=1.0))\n",
    "df_.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df, df_test_ = train_test_split(df_, test_size=0.2,\n",
    "                                stratify=df_['score_label'],\n",
    "                                random_state = 8848)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 40.81 %\n",
      "Class 1 59.19 %\n"
     ]
    }
   ],
   "source": [
    "# Label distribution\n",
    "count_0_1=df.groupby(\"score_label\").count()['subreddit'].values\n",
    "print (f\"Class 0 {np.round(100*count_0_1[0]/np.sum(count_0_1), 2)} %\")\n",
    "print (f\"Class 1 {np.round(100*count_0_1[1]/np.sum(count_0_1), 2)} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def prepare_TFIDF(df, feature_col, target_col):\n",
    "    df = df[[feature_col, target_col]]\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2,\n",
    "                                         stratify=df[target_col],\n",
    "                                         random_state = 8848)\n",
    "    vectorizer = TfidfVectorizer(use_idf=True, max_df=0.95)\n",
    "    \n",
    "    vectorizer.fit_transform(df_train[feature_col].values)\n",
    "    \n",
    "    X_train = vectorizer.transform(df_train[feature_col].values)\n",
    "    X_test  = vectorizer.transform(df_test[feature_col].values)\n",
    "\n",
    "    y_train = df_train[target_col].values\n",
    "    y_test  = df_test[target_col].values\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Accuracy\", \"Pr_0\", \"Pr_1\", \"Re_0\", \"Re_1\", \"F1_0\", \"F1_1\"]\n",
    "df_res = pd.DataFrame([], columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dataframe to store results\n",
    "def update_results(df_res, model, X, y, model_name):\n",
    "    ypred = model.predict(X)\n",
    "    ac = accuracy_score(y.ravel(), ypred.ravel() )\n",
    "    pr, re, f1, _ = precision_recall_fscore_support(y.ravel(), ypred.ravel() )\n",
    "    df_res.loc[model_name, \"Accuracy\"] = np.round(100*ac, 2)\n",
    "    df_res.loc[model_name, [\"Pr_0\", \"Pr_1\"]] = np.round(100*pr, 2)\n",
    "    df_res.loc[model_name, [\"Re_0\", \"Re_1\"]] = np.round(100*re, 2)\n",
    "    df_res.loc[model_name, [\"F1_0\", \"F1_1\"]] = np.round(100*f1, 2)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(df=df, xcol=\"body_processed\", ycol=\"score_label\"):\n",
    "    X_train, X_test, y_train, y_test, vectorizer= prepare_TFIDF(df,\n",
    "                                                                xcol,\n",
    "                                                                ycol)\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Body only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pr_0</th>\n",
       "      <th>Pr_1</th>\n",
       "      <th>Re_0</th>\n",
       "      <th>Re_1</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>F1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR : Body Only</th>\n",
       "      <td>71.84</td>\n",
       "      <td>65.26</td>\n",
       "      <td>76.51</td>\n",
       "      <td>66.31</td>\n",
       "      <td>75.66</td>\n",
       "      <td>65.78</td>\n",
       "      <td>76.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title Only</th>\n",
       "      <td>68.76</td>\n",
       "      <td>67.75</td>\n",
       "      <td>69.14</td>\n",
       "      <td>44.77</td>\n",
       "      <td>85.30</td>\n",
       "      <td>53.92</td>\n",
       "      <td>76.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title + Body</th>\n",
       "      <td>75.52</td>\n",
       "      <td>73.54</td>\n",
       "      <td>76.58</td>\n",
       "      <td>62.52</td>\n",
       "      <td>84.49</td>\n",
       "      <td>67.58</td>\n",
       "      <td>80.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title + Body + Author</th>\n",
       "      <td>81.21</td>\n",
       "      <td>80.59</td>\n",
       "      <td>81.56</td>\n",
       "      <td>71.08</td>\n",
       "      <td>88.19</td>\n",
       "      <td>75.54</td>\n",
       "      <td>84.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM: Body only [CV]</th>\n",
       "      <td>41.02</td>\n",
       "      <td>38.55</td>\n",
       "      <td>50.50</td>\n",
       "      <td>74.96</td>\n",
       "      <td>17.62</td>\n",
       "      <td>50.92</td>\n",
       "      <td>26.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM: Title + Body [CV]</th>\n",
       "      <td>59.19</td>\n",
       "      <td>49.84</td>\n",
       "      <td>59.26</td>\n",
       "      <td>0.90</td>\n",
       "      <td>99.38</td>\n",
       "      <td>1.77</td>\n",
       "      <td>74.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy   Pr_0   Pr_1   Re_0   Re_1   F1_0   F1_1\n",
       "Method                                                                        \n",
       "LR : Body Only                 71.84  65.26  76.51  66.31  75.66  65.78  76.08\n",
       "LR : Title Only                68.76  67.75  69.14  44.77  85.30  53.92  76.37\n",
       "LR : Title + Body              75.52  73.54  76.58  62.52  84.49  67.58  80.34\n",
       "LR : Title + Body + Author     81.21  80.59  81.56  71.08  88.19  75.54  84.75\n",
       "SVM: Body only [CV]            41.02  38.55  50.50  74.96  17.62  50.92  26.12\n",
       "SVM: Title + Body [CV]         59.19  49.84  59.26   0.90  99.38   1.77  74.24"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, X_train, X_test, y_train, y_test = logistic_regression(xcol=\"body_processed\")\n",
    "df_res = update_results(df_res, model, X_test, y_test, 'LR : Body Only')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 93647,  47775],\n",
       "       [ 50063, 155035]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_train, model.predict(X_train))\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Title only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pr_0</th>\n",
       "      <th>Pr_1</th>\n",
       "      <th>Re_0</th>\n",
       "      <th>Re_1</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>F1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR : Body Only</th>\n",
       "      <td>71.84</td>\n",
       "      <td>65.26</td>\n",
       "      <td>76.51</td>\n",
       "      <td>66.31</td>\n",
       "      <td>75.66</td>\n",
       "      <td>65.78</td>\n",
       "      <td>76.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title Only</th>\n",
       "      <td>65.67</td>\n",
       "      <td>62.17</td>\n",
       "      <td>66.95</td>\n",
       "      <td>40.60</td>\n",
       "      <td>82.96</td>\n",
       "      <td>49.12</td>\n",
       "      <td>74.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title + Body</th>\n",
       "      <td>75.52</td>\n",
       "      <td>73.54</td>\n",
       "      <td>76.58</td>\n",
       "      <td>62.52</td>\n",
       "      <td>84.49</td>\n",
       "      <td>67.58</td>\n",
       "      <td>80.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title + Body + Author</th>\n",
       "      <td>81.21</td>\n",
       "      <td>80.59</td>\n",
       "      <td>81.56</td>\n",
       "      <td>71.08</td>\n",
       "      <td>88.19</td>\n",
       "      <td>75.54</td>\n",
       "      <td>84.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM: Body only [CV]</th>\n",
       "      <td>41.02</td>\n",
       "      <td>38.55</td>\n",
       "      <td>50.50</td>\n",
       "      <td>74.96</td>\n",
       "      <td>17.62</td>\n",
       "      <td>50.92</td>\n",
       "      <td>26.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM: Title + Body [CV]</th>\n",
       "      <td>59.19</td>\n",
       "      <td>49.84</td>\n",
       "      <td>59.26</td>\n",
       "      <td>0.90</td>\n",
       "      <td>99.38</td>\n",
       "      <td>1.77</td>\n",
       "      <td>74.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy   Pr_0   Pr_1   Re_0   Re_1   F1_0   F1_1\n",
       "Method                                                                        \n",
       "LR : Body Only                 71.84  65.26  76.51  66.31  75.66  65.78  76.08\n",
       "LR : Title Only                65.67  62.17  66.95  40.60  82.96  49.12  74.10\n",
       "LR : Title + Body              75.52  73.54  76.58  62.52  84.49  67.58  80.34\n",
       "LR : Title + Body + Author     81.21  80.59  81.56  71.08  88.19  75.54  84.75\n",
       "SVM: Body only [CV]            41.02  38.55  50.50  74.96  17.62  50.92  26.12\n",
       "SVM: Title + Body [CV]         59.19  49.84  59.26   0.90  99.38   1.77  74.24"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, X_train, X_test, y_train, y_test = logistic_regression(xcol=\"title_processed\")\n",
    "df_res = update_results(df_res, model, X_test, y_test, 'LR : Title Only')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Title + Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pr_0</th>\n",
       "      <th>Pr_1</th>\n",
       "      <th>Re_0</th>\n",
       "      <th>Re_1</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>F1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR : Body Only</th>\n",
       "      <td>71.84</td>\n",
       "      <td>65.26</td>\n",
       "      <td>76.51</td>\n",
       "      <td>66.31</td>\n",
       "      <td>75.66</td>\n",
       "      <td>65.78</td>\n",
       "      <td>76.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title Only</th>\n",
       "      <td>65.67</td>\n",
       "      <td>62.17</td>\n",
       "      <td>66.95</td>\n",
       "      <td>40.60</td>\n",
       "      <td>82.96</td>\n",
       "      <td>49.12</td>\n",
       "      <td>74.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title + Body</th>\n",
       "      <td>73.07</td>\n",
       "      <td>69.65</td>\n",
       "      <td>74.94</td>\n",
       "      <td>60.29</td>\n",
       "      <td>81.88</td>\n",
       "      <td>64.63</td>\n",
       "      <td>78.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title + Body + Author</th>\n",
       "      <td>81.21</td>\n",
       "      <td>80.59</td>\n",
       "      <td>81.56</td>\n",
       "      <td>71.08</td>\n",
       "      <td>88.19</td>\n",
       "      <td>75.54</td>\n",
       "      <td>84.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM: Body only [CV]</th>\n",
       "      <td>41.02</td>\n",
       "      <td>38.55</td>\n",
       "      <td>50.50</td>\n",
       "      <td>74.96</td>\n",
       "      <td>17.62</td>\n",
       "      <td>50.92</td>\n",
       "      <td>26.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM: Title + Body [CV]</th>\n",
       "      <td>59.19</td>\n",
       "      <td>49.84</td>\n",
       "      <td>59.26</td>\n",
       "      <td>0.90</td>\n",
       "      <td>99.38</td>\n",
       "      <td>1.77</td>\n",
       "      <td>74.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy   Pr_0   Pr_1   Re_0   Re_1   F1_0   F1_1\n",
       "Method                                                                        \n",
       "LR : Body Only                 71.84  65.26  76.51  66.31  75.66  65.78  76.08\n",
       "LR : Title Only                65.67  62.17  66.95  40.60  82.96  49.12  74.10\n",
       "LR : Title + Body              73.07  69.65  74.94  60.29  81.88  64.63  78.26\n",
       "LR : Title + Body + Author     81.21  80.59  81.56  71.08  88.19  75.54  84.75\n",
       "SVM: Body only [CV]            41.02  38.55  50.50  74.96  17.62  50.92  26.12\n",
       "SVM: Title + Body [CV]         59.19  49.84  59.26   0.90  99.38   1.77  74.24"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, X_train, X_test, y_train, y_test = logistic_regression(xcol=\"body_and_title\")\n",
    "df_res = update_results(df_res, model, X_test, y_test, 'LR : Title + Body')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Title + Body + author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pr_0</th>\n",
       "      <th>Pr_1</th>\n",
       "      <th>Re_0</th>\n",
       "      <th>Re_1</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>F1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR : Body Only</th>\n",
       "      <td>71.84</td>\n",
       "      <td>65.26</td>\n",
       "      <td>76.51</td>\n",
       "      <td>66.31</td>\n",
       "      <td>75.66</td>\n",
       "      <td>65.78</td>\n",
       "      <td>76.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title Only</th>\n",
       "      <td>65.67</td>\n",
       "      <td>62.17</td>\n",
       "      <td>66.95</td>\n",
       "      <td>40.60</td>\n",
       "      <td>82.96</td>\n",
       "      <td>49.12</td>\n",
       "      <td>74.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title + Body</th>\n",
       "      <td>73.07</td>\n",
       "      <td>69.65</td>\n",
       "      <td>74.94</td>\n",
       "      <td>60.29</td>\n",
       "      <td>81.88</td>\n",
       "      <td>64.63</td>\n",
       "      <td>78.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title + Body + Author</th>\n",
       "      <td>75.90</td>\n",
       "      <td>73.31</td>\n",
       "      <td>77.34</td>\n",
       "      <td>64.38</td>\n",
       "      <td>83.84</td>\n",
       "      <td>68.56</td>\n",
       "      <td>80.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM: Body only [CV]</th>\n",
       "      <td>41.02</td>\n",
       "      <td>38.55</td>\n",
       "      <td>50.50</td>\n",
       "      <td>74.96</td>\n",
       "      <td>17.62</td>\n",
       "      <td>50.92</td>\n",
       "      <td>26.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM: Title + Body [CV]</th>\n",
       "      <td>59.19</td>\n",
       "      <td>49.84</td>\n",
       "      <td>59.26</td>\n",
       "      <td>0.90</td>\n",
       "      <td>99.38</td>\n",
       "      <td>1.77</td>\n",
       "      <td>74.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy   Pr_0   Pr_1   Re_0   Re_1   F1_0   F1_1\n",
       "Method                                                                        \n",
       "LR : Body Only                 71.84  65.26  76.51  66.31  75.66  65.78  76.08\n",
       "LR : Title Only                65.67  62.17  66.95  40.60  82.96  49.12  74.10\n",
       "LR : Title + Body              73.07  69.65  74.94  60.29  81.88  64.63  78.26\n",
       "LR : Title + Body + Author     75.90  73.31  77.34  64.38  83.84  68.56  80.46\n",
       "SVM: Body only [CV]            41.02  38.55  50.50  74.96  17.62  50.92  26.12\n",
       "SVM: Title + Body [CV]         59.19  49.84  59.26   0.90  99.38   1.77  74.24"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, X_train, X_test, y_train, y_test = logistic_regression(xcol=\"body_title_and_author\")\n",
    "df_res = update_results(df_res, model, X_test, y_test, 'LR : Title + Body + Author')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save LR results\n",
    "dftmp = df_res.drop([\"SVM: Body only [CV]\", \"SVM: Title + Body [CV]\"] , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftmp.to_csv(\"df_res_LR.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Results\n",
    "| Method | Accuracy | Pr_0 | Pr_1 | Re_0 | Re_1 | F1_0 | F1_1 | \n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| LR : Body Only | 71.82 | 65.29 | 76.43 | 66.11 | 75.77 | 65.7 | 76.09 | \n",
    "| LR : Title Only | 68.76 | 67.75 | 69.14 | 44.77 | 85.3 | 53.92 | 76.37 | \n",
    "| LR : Title + Body | 75.52 | 73.54 | 76.58 | 62.52 | 84.49 | 67.58 | 80.34 | \n",
    "| LR : Title + Body + Author | 81.21 | 80.59 | 81.56 | 71.08 | 88.19 | 75.54 | 84.75 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pr_0</th>\n",
       "      <th>Pr_1</th>\n",
       "      <th>Re_0</th>\n",
       "      <th>Re_1</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>F1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR : Body Only</th>\n",
       "      <td>71.82</td>\n",
       "      <td>65.29</td>\n",
       "      <td>76.43</td>\n",
       "      <td>66.11</td>\n",
       "      <td>75.77</td>\n",
       "      <td>65.70</td>\n",
       "      <td>76.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title Only</th>\n",
       "      <td>68.76</td>\n",
       "      <td>67.75</td>\n",
       "      <td>69.14</td>\n",
       "      <td>44.77</td>\n",
       "      <td>85.30</td>\n",
       "      <td>53.92</td>\n",
       "      <td>76.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title + Body</th>\n",
       "      <td>75.52</td>\n",
       "      <td>73.54</td>\n",
       "      <td>76.58</td>\n",
       "      <td>62.52</td>\n",
       "      <td>84.49</td>\n",
       "      <td>67.58</td>\n",
       "      <td>80.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title + Body + Author</th>\n",
       "      <td>81.21</td>\n",
       "      <td>80.59</td>\n",
       "      <td>81.56</td>\n",
       "      <td>71.08</td>\n",
       "      <td>88.19</td>\n",
       "      <td>75.54</td>\n",
       "      <td>84.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy   Pr_0   Pr_1   Re_0   Re_1   F1_0   F1_1\n",
       "Method                                                                        \n",
       "LR : Body Only                 71.82  65.29  76.43  66.11  75.77  65.70  76.09\n",
       "LR : Title Only                68.76  67.75  69.14  44.77  85.30  53.92  76.37\n",
       "LR : Title + Body              75.52  73.54  76.58  62.52  84.49  67.58  80.34\n",
       "LR : Title + Body + Author     81.21  80.59  81.56  71.08  88.19  75.54  84.75"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the LR results\n",
    "#df_res = pd.read_csv('df_res_LR.csv')\n",
    "#df_res.set_index(\"Method\", drop=True, inplace=True)\n",
    "#df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcol=\"body_processed\";\n",
    "ycol=\"score_label\"\n",
    "X_train, X_test, y_train, y_test, vectorizer= prepare_TFIDF(df,\n",
    "                                                            xcol,\n",
    "                                                            ycol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_CV_SVM(params, df=df, xcol=\"body_processed\", ycol=\"score_label\", N_cv=5):\n",
    "    X_train, X_test, y_train, y_test, vectorizer = prepare_TFIDF(df,\n",
    "                                                                xcol,\n",
    "                                                                ycol)\n",
    "    \n",
    "    model_grid = GridSearchCV(estimator = SVC(kernel='rbf', degree=3, max_iter=1000),\n",
    "                              param_grid = params,\n",
    "                              cv = StratifiedKFold(n_splits=N_cv,\n",
    "                                                   random_state=8848,\n",
    "                                                   shuffle=True),\n",
    "                              verbose=3)\n",
    "    grid_res = model_grid.fit(X_train, y_train)\n",
    "    print ( \"Best Score:\", grid_res.best_score_, grid_res.best_params_)\n",
    "    return model_grid, X_train, X_test, y_train, y_test, grid_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END ...............................C=5;, score=0.688 total time=  36.6s\n",
      "[CV 2/5] END ...............................C=5;, score=0.686 total time=  30.8s\n",
      "[CV 3/5] END ...............................C=5;, score=0.665 total time=  27.2s\n",
      "[CV 4/5] END ...............................C=5;, score=0.660 total time=  30.3s\n",
      "[CV 5/5] END ...............................C=5;, score=0.690 total time=  25.5s\n",
      "[CV 1/5] END ..............................C=10;, score=0.686 total time=  27.9s\n",
      "[CV 2/5] END ..............................C=10;, score=0.377 total time=  42.8s\n",
      "[CV 3/5] END ..............................C=10;, score=0.687 total time=  24.7s\n",
      "[CV 4/5] END ..............................C=10;, score=0.701 total time=  21.7s\n",
      "[CV 5/5] END ..............................C=10;, score=0.654 total time=  22.9s\n",
      "[CV 1/5] END ..............................C=15;, score=0.652 total time=  34.6s\n",
      "[CV 2/5] END ..............................C=15;, score=0.651 total time=  33.2s\n",
      "[CV 3/5] END ..............................C=15;, score=0.682 total time=  24.4s\n",
      "[CV 4/5] END ..............................C=15;, score=0.694 total time=  26.4s\n",
      "[CV 5/5] END ..............................C=15;, score=0.651 total time=  26.5s\n",
      "Best Score: 0.6776174535380353 {'C': 5}\n"
     ]
    }
   ],
   "source": [
    "params = {\"C\":[5, 10, 15]}\n",
    "\n",
    "model_grid, X_train, X_test, y_train, y_test, grid_res = grid_search_CV_SVM(params,\n",
    "                                                                            xcol=\"body_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pr_0</th>\n",
       "      <th>Pr_1</th>\n",
       "      <th>Re_0</th>\n",
       "      <th>Re_1</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>F1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR : Body Only</th>\n",
       "      <td>71.82</td>\n",
       "      <td>65.29</td>\n",
       "      <td>76.43</td>\n",
       "      <td>66.11</td>\n",
       "      <td>75.77</td>\n",
       "      <td>65.70</td>\n",
       "      <td>76.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title Only</th>\n",
       "      <td>68.76</td>\n",
       "      <td>67.75</td>\n",
       "      <td>69.14</td>\n",
       "      <td>44.77</td>\n",
       "      <td>85.30</td>\n",
       "      <td>53.92</td>\n",
       "      <td>76.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title + Body</th>\n",
       "      <td>75.52</td>\n",
       "      <td>73.54</td>\n",
       "      <td>76.58</td>\n",
       "      <td>62.52</td>\n",
       "      <td>84.49</td>\n",
       "      <td>67.58</td>\n",
       "      <td>80.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title + Body + Author</th>\n",
       "      <td>81.21</td>\n",
       "      <td>80.59</td>\n",
       "      <td>81.56</td>\n",
       "      <td>71.08</td>\n",
       "      <td>88.19</td>\n",
       "      <td>75.54</td>\n",
       "      <td>84.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM: Body only [CV]</th>\n",
       "      <td>41.02</td>\n",
       "      <td>38.55</td>\n",
       "      <td>50.50</td>\n",
       "      <td>74.96</td>\n",
       "      <td>17.62</td>\n",
       "      <td>50.92</td>\n",
       "      <td>26.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy   Pr_0   Pr_1   Re_0   Re_1   F1_0   F1_1\n",
       "Method                                                                        \n",
       "LR : Body Only                 71.82  65.29  76.43  66.11  75.77  65.70  76.09\n",
       "LR : Title Only                68.76  67.75  69.14  44.77  85.30  53.92  76.37\n",
       "LR : Title + Body              75.52  73.54  76.58  62.52  84.49  67.58  80.34\n",
       "LR : Title + Body + Author     81.21  80.59  81.56  71.08  88.19  75.54  84.75\n",
       "SVM: Body only [CV]            41.02  38.55  50.50  74.96  17.62  50.92  26.12"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = update_results(df_res, model_grid, X_test, y_test, 'SVM: Body only [CV]')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END ...............................C=5;, score=0.517 total time=  38.6s\n",
      "[CV 2/5] END ...............................C=5;, score=0.625 total time=  26.1s\n",
      "[CV 3/5] END ...............................C=5;, score=0.591 total time=  34.3s\n",
      "[CV 4/5] END ...............................C=5;, score=0.489 total time=  36.5s\n",
      "[CV 5/5] END ...............................C=5;, score=0.595 total time=  33.4s\n",
      "[CV 1/5] END ..............................C=10;, score=0.454 total time=  32.3s\n",
      "[CV 2/5] END ..............................C=10;, score=0.495 total time=  33.7s\n",
      "[CV 3/5] END ..............................C=10;, score=0.467 total time=  37.0s\n",
      "[CV 4/5] END ..............................C=10;, score=0.411 total time=  31.4s\n",
      "[CV 5/5] END ..............................C=10;, score=0.432 total time=  28.2s\n",
      "Best Score: 0.5632113586517373 {'C': 5}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pr_0</th>\n",
       "      <th>Pr_1</th>\n",
       "      <th>Re_0</th>\n",
       "      <th>Re_1</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>F1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR : Body Only</th>\n",
       "      <td>71.82</td>\n",
       "      <td>65.29</td>\n",
       "      <td>76.43</td>\n",
       "      <td>66.11</td>\n",
       "      <td>75.77</td>\n",
       "      <td>65.70</td>\n",
       "      <td>76.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title Only</th>\n",
       "      <td>68.76</td>\n",
       "      <td>67.75</td>\n",
       "      <td>69.14</td>\n",
       "      <td>44.77</td>\n",
       "      <td>85.30</td>\n",
       "      <td>53.92</td>\n",
       "      <td>76.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title + Body</th>\n",
       "      <td>75.52</td>\n",
       "      <td>73.54</td>\n",
       "      <td>76.58</td>\n",
       "      <td>62.52</td>\n",
       "      <td>84.49</td>\n",
       "      <td>67.58</td>\n",
       "      <td>80.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR : Title + Body + Author</th>\n",
       "      <td>81.21</td>\n",
       "      <td>80.59</td>\n",
       "      <td>81.56</td>\n",
       "      <td>71.08</td>\n",
       "      <td>88.19</td>\n",
       "      <td>75.54</td>\n",
       "      <td>84.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM: Body only [CV]</th>\n",
       "      <td>41.02</td>\n",
       "      <td>38.55</td>\n",
       "      <td>50.50</td>\n",
       "      <td>74.96</td>\n",
       "      <td>17.62</td>\n",
       "      <td>50.92</td>\n",
       "      <td>26.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM: Title + Body [CV]</th>\n",
       "      <td>59.19</td>\n",
       "      <td>49.84</td>\n",
       "      <td>59.26</td>\n",
       "      <td>0.90</td>\n",
       "      <td>99.38</td>\n",
       "      <td>1.77</td>\n",
       "      <td>74.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy   Pr_0   Pr_1   Re_0   Re_1   F1_0   F1_1\n",
       "Method                                                                        \n",
       "LR : Body Only                 71.82  65.29  76.43  66.11  75.77  65.70  76.09\n",
       "LR : Title Only                68.76  67.75  69.14  44.77  85.30  53.92  76.37\n",
       "LR : Title + Body              75.52  73.54  76.58  62.52  84.49  67.58  80.34\n",
       "LR : Title + Body + Author     81.21  80.59  81.56  71.08  88.19  75.54  84.75\n",
       "SVM: Body only [CV]            41.02  38.55  50.50  74.96  17.62  50.92  26.12\n",
       "SVM: Title + Body [CV]         59.19  49.84  59.26   0.90  99.38   1.77  74.24"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"C\":[5, 10]}\n",
    "\n",
    "model_grid, X_train, X_test, y_train, y_test, grid_res = grid_search_CV_SVM(params,\n",
    "                                                                            xcol=\"body_and_title\")\n",
    "\n",
    "df_res = update_results(df_res, model_grid, X_test, y_test, 'SVM: Title + Body [CV]')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85992, 86630)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred), len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6852937781369041 54784 51275\n"
     ]
    }
   ],
   "source": [
    "model_svm = SVC(C=10.0, kernel='rbf',\n",
    "                degree=3, gamma='scale',\n",
    "                max_iter=1000)\n",
    "model_svm.fit(X_train, y_train)\n",
    "pred = model_svm.predict(X_test)\n",
    "print ( accuracy_score(y_test, pred),\n",
    "       pred.sum(),\n",
    "       y_test.sum()\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6874379545192196\n"
     ]
    }
   ],
   "source": [
    "print ( accuracy_score(y_train, model_svm.predict(X_train)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVM(df=df, xcol=\"body_processed\", ycol=\"score_label\"):\n",
    "    X_train, X_test, y_train, y_test, vectorizer= prepare_TFIDF(df,\n",
    "                                                                xcol,\n",
    "                                                                ycol)\n",
    "\n",
    "    model_svm = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', max_iter=500)\n",
    "    model_svm.fit(X_train, y_train)\n",
    "    return model_svm, X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4cef9b7a69ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_svm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_SVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"body_processed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-74e2025f3387>\u001b[0m in \u001b[0;36mtrain_SVM\u001b[0;34m(df, xcol, ycol)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_SVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"body_processed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mycol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"score_label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     X_train, X_test, y_train, y_test, vectorizer= prepare_TFIDF(df,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                                 \u001b[0mxcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                 ycol)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-07a3787563b4>\u001b[0m in \u001b[0;36mprepare_TFIDF\u001b[0;34m(df, feature_col, target_column)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1844\u001b[0m         \"\"\"\n\u001b[1;32m   1845\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1846\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1847\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1203\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[1;32m    218\u001b[0m                              \"unicode string.\")\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "model_svm, X_train, X_test, y_train, y_test = train_SVM(df=df, xcol=\"body_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', max_iter=500)\n",
    "model_svm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(df=df, xcol=\"body_processed\", ycol=\"score_label\"):\n",
    "    X_train, X_test, y_train, y_test, vectorizer= prepare_TFIDF(df,\n",
    "                                                                xcol,\n",
    "                                                                ycol)\n",
    "    model = DecisionTreeClassifier(random_state = 8848, max_depth=2)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree with Body + Title + Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, X_train, X_test, y_train, y_test = decision_tree(xcol=\"body_title_and_author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, X_train, X_test, y_train, y_test = decision_tree(xcol=\"body_title_and_author\")\n",
    "df_res = update_results(df_res, model, X_train, y_train, 'DT : Title + Body + Author')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree : Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_CV(params, df=df, xcol=\"body_processed\", ycol=\"label\", N_cv=5):\n",
    "    X_train, X_test, y_train, y_test, vectorizer = prepare_TFIDF(df,\n",
    "                                                                xcol,\n",
    "                                                                ycol)\n",
    "    \n",
    "    model_grid = GridSearchCV(estimator = DecisionTreeClassifier(random_state = 8848),\n",
    "                              param_grid = params,\n",
    "                              cv = StratifiedKFold(n_splits=N_cv,\n",
    "                                                   random_state=8848,\n",
    "                                                   shuffle=True),\n",
    "                              verbose=3)\n",
    "    grid_res = model_grid.fit(X_train, y_train)\n",
    "    print ( \"Best Score:\", grid_res.best_score_, grid_res.best_params_)\n",
    "    return model_grid, X_train, X_test, y_train, y_test, grid_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree : CV, Body Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"max_depth\": [4, 5, 6] }\n",
    "model, X_train, X_test, y_train, y_test, grid_res = grid_search_CV(params,\n",
    "                                                                   xcol=\"body_processed\")\n",
    "df_res = update_results(df_res, model, X_train, y_train, 'DT : Body Only [CV]')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"max_depth\": [4, 5, 6, 10, 20] }\n",
    "model, X_train, X_test, y_train, y_test, grid_res = grid_search_CV(params,\n",
    "                                                                   xcol=\"title_processed\")\n",
    "df_res = update_results(df_res, model, X_train, y_train, 'DT : Title Only [CV]')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"max_depth\": [10, 15, 20, 25] }\n",
    "model, X_train, X_test, y_train, y_test, grid_res = grid_search_CV(params,\n",
    "                                                                   xcol=\"title_processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Body only\n",
    "X_train, X_test, y_train, y_test, vectorizer= prepare_TFIDF(df,\n",
    "                                                            \"body_processed\",\n",
    "                                                            \"label\")\n",
    "\n",
    "model = DecisionTreeClassifier(random_state = 8848)\n",
    "model.fit(X_train, y_train)\n",
    "df_res = update_results(df_res, model, X_train, y_train,'DT : Body Only')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title only\n",
    "X_train, X_test, y_train, y_test, vectorizer= prepare_TFIDF(df,\n",
    "                                                            \"title_processed\",\n",
    "                                                            \"label\")\n",
    "\n",
    "model = DecisionTreeClassifier(random_state = 8848)\n",
    "model.fit(X_train, y_train)\n",
    "df_res = update_results(df_res, model, X_train, y_train,'DT : Title Only')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Body + Title only\n",
    "X_train, X_test, y_train, y_test, vectorizer= prepare_TFIDF(df,\n",
    "                                                            \"body_and_title\",\n",
    "                                                            \"label\")\n",
    "\n",
    "model = DecisionTreeClassifier(random_state = 8848)\n",
    "model.fit(X_train, y_train)\n",
    "df_res = update_results(df_res, model, X_train, y_train,'DT : Title + Body')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree: Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_CV(model, params, X_train, y_train):\n",
    "    #max_depths = \n",
    "    #\n",
    "    model_grid = GridSearchCV(estimator = model,\n",
    "                              param_grid = params,\n",
    "                              cv = StratifiedKFold(n_splits=5, random_state=8848, shuffle=True), \n",
    "                              verbose=2)\n",
    "    grid_res = model_grid.fit(X_train, y_train)\n",
    "    print ( \"Besy Score:\", grid_res.best_score_, grid_res.best_params_)\n",
    "    return grid_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state = 8848)\n",
    "params = {\"max_depth\": [5, 6, 7, 8] }\n",
    "X_train, X_test, y_train, y_test, vectorizer= prepare_TFIDF(df,\n",
    "                                                            \"title_processed\",\n",
    "                                                            \"label\")\n",
    "\n",
    "grid_res = grid_search_CV(model, params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state = 8848, max_depth=6)\n",
    "model.fit(X_train, y_train)\n",
    "df_res = update_results(df_res, model, X_train, y_train,'DT : Title Only [CV]')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree: Grid Search CV Title + Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state = 8848)\n",
    "params = {\"max_depth\": [7, 8, 9, 10] }\n",
    "X_train, X_test, y_train, y_test, vectorizer= prepare_TFIDF(df,\n",
    "                                                            \"body_and_title\",\n",
    "                                                            \"label\")\n",
    "\n",
    "grid_res = grid_search_CV(model, params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state = 8848, max_depth=9)\n",
    "model.fit(X_train, y_train)\n",
    "df_res = update_results(df_res, model, X_train, y_train,'DT : Title + Body [CV]')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state = 8848)\n",
    "params = {\"max_depth\": [7, 8, 9, 10] }\n",
    "X_train, X_test, y_train, y_test, vectorizer= prepare_TFIDF(df,\n",
    "                                                            \"body_processed\",\n",
    "                                                            \"label\")\n",
    "grid_res = grid_search_CV(model, params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state = 8848, max_depth=9)\n",
    "model.fit(X_train, y_train)\n",
    "df_res = update_results(df_res, model, X_train, y_train,'DT : Body Only [CV]')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Body only\n",
    "X_train, X_test, y_train, y_test, vectorizer= prepare_TFIDF(df,\n",
    "                                                            \"body_processed\",\n",
    "                                                            \"label\")\n",
    "\n",
    "model = RandomForestClassifier(random_state = 8848)\n",
    "model.fit(X_train, y_train)\n",
    "df_res = update_results(df_res, model, X_train, y_train,'RF : Body Only')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest : Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state = 8848)\n",
    "params = {\"max_depth\": [7, 8], \"n_estimators\":[100, 200] }\n",
    "X_train, X_test, y_train, y_test, vectorizer= prepare_TFIDF(df,\n",
    "                                                            \"body_processed\",\n",
    "                                                            \"label\")\n",
    "\n",
    "grid_res = grid_search_CV(model, params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state = 8848)\n",
    "params = {\"max_depth\": [8, 9, 10], \"n_estimators\":[200, 300] }\n",
    "X_train, X_test, y_train, y_test, vectorizer= prepare_TFIDF(df,\n",
    "                                                            \"body_processed\",\n",
    "                                                            \"label\")\n",
    "\n",
    "grid_res = grid_search_CV(model, params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Body only\n",
    "model = RandomForestClassifier(random_state = 8848, max_depth= 10, n_estimators=300)\n",
    "model.fit(X_train, y_train)\n",
    "df_res = update_results(df_res, model, X_train, y_train,'RF : Body Only [CV]')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Few words:**\n",
    "- The GridSearchCV takes the default score as *accuracy* I guess.\n",
    "- We may have to use a differnt scoring as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
